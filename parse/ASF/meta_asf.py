#!/usr/bin/env python3
"""
Meta-script principal pour le traitement complet des donn√©es ASF.

Ce script orchestre l'ensemble du workflow de traitement des donn√©es:
1. Ex√©cution de tous les scripts de parsing (page*/raw_data/parse_asf_*.py)
2. Consolidation par page: fusion des asf_*.csv en ASF_page*_*.csv
3. Validation du triplet par page
4. Fusion finale: fusion des ASF_page*_*.csv en ASF_*.csv
5. Validation du triplet final

R√©sultats par page:
- page*/ASF_page*_data_price_close_2025.csv
- page*/ASF_page*_data_price_open_2025.csv
- page*/ASF_page*_toll_info.csv

R√©sultats finaux:
- ASF_data_price_close_2025.csv
- ASF_data_price_open_2025.csv
- ASF_toll_info.csv

Auteur: OpenCode
Date: 2026-01-29
"""

import subprocess
import sys
from pathlib import Path
from typing import List


class MetaScriptError(Exception):
    """Exception lev√©e lors d'erreurs du meta-script."""

    pass


def run_command(script_path: Path, args: List[str] = None) -> None:
    """
    Ex√©cute un script Python avec des arguments optionnels.

    Args:
        script_path: Chemin du script √† ex√©cuter
        args: Liste d'arguments √† passer au script

    Raises:
        MetaScriptError: Si le script √©choue
    """
    cmd = [sys.executable, str(script_path)]
    if args:
        cmd.extend(args)

    result = subprocess.run(cmd, cwd=script_path.parent)

    if result.returncode != 0:
        raise MetaScriptError(
            f"Le script {script_path.name} a √©chou√© avec le code {result.returncode}"
        )


def find_csv_files(base_dir: Path, pattern: str) -> List[str]:
    """
    Trouve tous les fichiers CSV correspondant √† un pattern.

    Args:
        base_dir: R√©pertoire de base
        pattern: Pattern de recherche (ex: "ASF_page*_data_price_close_2025.csv")

    Returns:
        Liste tri√©e des chemins de fichiers trouv√©s
    """
    files = sorted(base_dir.glob(f"page*/{pattern}"))
    return [str(f) for f in files]


def find_page_directories(base_dir: Path) -> List[Path]:
    """
    Trouve tous les r√©pertoires page*.

    Args:
        base_dir: R√©pertoire de base

    Returns:
        Liste tri√©e des r√©pertoires page*
    """
    return sorted([d for d in base_dir.glob("page*") if d.is_dir()])


def consolidate_page_csvs(page_dir: Path, merge_script: Path) -> None:
    """
    Consolide tous les fichiers CSV d'une page en cr√©ant le triplet ASF_page*_*.csv

    Args:
        page_dir: R√©pertoire de la page
        merge_script: Chemin du script merge_csv_files.py

    Raises:
        MetaScriptError: Si la fusion √©choue
    """
    page_name = page_dir.name
    print(f"\n  üìÅ Consolidation de {page_name}...")

    # Chercher dans raw_data/ et √† la racine de la page
    raw_data_dir = page_dir / "raw_data"
    search_dirs = [page_dir, raw_data_dir] if raw_data_dir.exists() else [page_dir]

    # Fusion des fichiers close
    close_pattern = "asf_prices_close_*.csv"
    close_files = []
    for search_dir in search_dirs:
        close_files.extend(sorted(search_dir.glob(close_pattern)))

    if close_files:
        output_close = page_dir / f"ASF_{page_name}_data_price_close_2025.csv"
        print(f"    üîπ Close: {len(close_files)} fichier(s) ‚Üí {output_close.name}")
        args = ["close", str(output_close)] + [str(f) for f in close_files]
        run_command(merge_script, args)
    else:
        # V√©rifier si le fichier consolid√© existe d√©j√†
        output_close = page_dir / f"ASF_{page_name}_data_price_close_2025.csv"
        if output_close.exists():
            print(f"    ‚úÖ Close: fichier consolid√© existant ({output_close.name})")
        else:
            print(f"    ‚ö†Ô∏è  Aucun fichier close trouv√© (pattern: {close_pattern})")

    # Fusion des fichiers open
    open_pattern = "asf_prices_open_*.csv"
    open_files = []
    for search_dir in search_dirs:
        open_files.extend(sorted(search_dir.glob(open_pattern)))

    if open_files:
        output_open = page_dir / f"ASF_{page_name}_data_price_open_2025.csv"
        print(f"    üîπ Open: {len(open_files)} fichier(s) ‚Üí {output_open.name}")
        args = ["open", str(output_open)] + [str(f) for f in open_files]
        run_command(merge_script, args)
    else:
        # V√©rifier si le fichier consolid√© existe d√©j√†
        output_open = page_dir / f"ASF_{page_name}_data_price_open_2025.csv"
        if output_open.exists():
            print(f"    ‚úÖ Open: fichier consolid√© existant ({output_open.name})")
        else:
            print(f"    ‚ö†Ô∏è  Aucun fichier open trouv√© (pattern: {open_pattern})")

    # Pour toll_info, on utilise directement le fichier ASF_page*_toll_info.csv s'il existe
    # Les fichiers asf_stations_*.csv sont des interm√©diaires qui n√©cessitent un enrichissement manuel
    toll_info_file = page_dir / f"ASF_{page_name}_toll_info.csv"
    if toll_info_file.exists():
        print(f"    ‚úÖ Toll Info: fichier existant ({toll_info_file.name})")
    else:
        print(f"    ‚ö†Ô∏è  Aucun fichier toll_info trouv√© ({toll_info_file.name})")

    print(f"    ‚úÖ Consolidation de {page_name} termin√©e")


def print_banner(title: str) -> None:
    """Affiche une banni√®re de section."""
    print(f"\n{'=' * 80}")
    print(f"  {title}")
    print(f"{'=' * 80}\n")


def print_summary(close_csv: Path, open_csv: Path, toll_info_csv: Path) -> None:
    """
    Affiche un r√©sum√© des fichiers g√©n√©r√©s.

    Args:
        close_csv: Chemin du fichier close
        open_csv: Chemin du fichier open
        toll_info_csv: Chemin du fichier toll_info
    """
    print_banner("üìä R√âSUM√â DES FICHIERS G√âN√âR√âS")

    # Compter les lignes de chaque fichier
    files_info = []

    for file_path, file_type in [
        (close_csv, "Prix Close"),
        (open_csv, "Prix Open"),
        (toll_info_csv, "Toll Info"),
    ]:
        if file_path.exists():
            with open(file_path, "r", encoding="utf-8") as f:
                line_count = sum(1 for _ in f) - 1  # -1 pour l'en-t√™te
            files_info.append((file_type, file_path.name, line_count))
        else:
            files_info.append((file_type, file_path.name, 0))

    # Afficher le tableau
    print(f"{'Type':<15} {'Fichier':<40} {'Lignes':>10}")
    print(f"{'-' * 15} {'-' * 40} {'-' * 10}")

    for file_type, filename, line_count in files_info:
        print(f"{file_type:<15} {filename:<40} {line_count:>10}")

    total_lines = sum(info[2] for info in files_info)
    print(f"{'-' * 15} {'-' * 40} {'-' * 10}")
    print(f"{'TOTAL':<15} {'':<40} {total_lines:>10}")

    print(f"\nüìÅ Tous les fichiers sont dans: {close_csv.parent}")
    print(f"\n{'=' * 80}\n")


def main():
    """Point d'entr√©e principal du meta-script."""
    base_dir = Path(__file__).parent

    print("\n" + "=" * 80)
    print("üöÄ META-SCRIPT ASF - TRAITEMENT COMPLET DES DONN√âES")
    print("=" * 80)
    print(f"\nüìÇ R√©pertoire de travail: {base_dir}")
    print(f"üéØ Objectif: G√©n√©rer les triplets par page puis le triplet final ASF")

    try:
        # ========================================
        # √âTAPE 1: Ex√©cuter tous les scripts de parsing
        # ========================================
        print_banner("√âTAPE 1/6: Ex√©cution des scripts de parsing")

        run_all_scripts_path = base_dir / "run_all_page_scripts.py"

        if run_all_scripts_path.exists():
            print("‚ñ∂Ô∏è  Ex√©cution de run_all_page_scripts.py...")
            run_command(run_all_scripts_path)
        else:
            print(
                "‚ö†Ô∏è  Script run_all_page_scripts.py non trouv√©, passage √† l'√©tape suivante"
            )

        # ========================================
        # √âTAPE 2: Consolidation par page
        # ========================================
        print_banner("√âTAPE 2/6: Consolidation des CSV par page")

        page_dirs = find_page_directories(base_dir)
        merge_script = base_dir / "../merge_csv_files.py"

        if not page_dirs:
            print("‚ö†Ô∏è  Aucun r√©pertoire page* trouv√©")
        else:
            print(
                f"üìã {len(page_dirs)} page(s) trouv√©e(s): {', '.join(d.name for d in page_dirs)}"
            )

            for page_dir in page_dirs:
                consolidate_page_csvs(page_dir, merge_script)

        # ========================================
        # √âTAPE 3: Validation des triplets par page
        # ========================================
        print_banner("√âTAPE 3/6: Validation des triplets par page")

        validate_script = base_dir / "../validate_triplet.py"
        validated_pages = 0

        for page_dir in page_dirs:
            page_name = page_dir.name
            close_file = page_dir / f"ASF_{page_name}_data_price_close_2025.csv"
            open_file = page_dir / f"ASF_{page_name}_data_price_open_2025.csv"
            toll_info_file = page_dir / f"ASF_{page_name}_toll_info.csv"

            # V√©rifier que le fichier toll_info existe (requis)
            if not toll_info_file.exists():
                print(f"  ‚ö†Ô∏è  {page_name}: pas de toll_info, validation ignor√©e")
                continue

            # Cr√©er des fichiers vides si close ou open n'existent pas
            if not close_file.exists():
                with open(close_file, "w", encoding="utf-8") as f:
                    f.write(
                        "name_from;name_to;distance;price1;price2;price3;price4;price5\n"
                    )

            if not open_file.exists():
                with open(open_file, "w", encoding="utf-8") as f:
                    f.write("name;distance;price1;price2;price3;price4;price5\n")

            print(f"  üîç Validation de {page_name}...")
            args = [str(close_file), str(open_file), str(toll_info_file)]
            run_command(validate_script, args)
            validated_pages += 1

        print(f"\n  ‚úÖ {validated_pages}/{len(page_dirs)} page(s) valid√©e(s)")

        # ========================================
        # √âTAPE 4: Fusion finale - Close
        # ========================================
        print_banner("√âTAPE 4/6: Fusion finale des fichiers Close")

        close_files = find_csv_files(base_dir, "ASF_page*_data_price_close_2025.csv")
        output_close = base_dir / "ASF_data_price_close_2025.csv"

        if close_files:
            print(f"üìã {len(close_files)} fichier(s) trouv√©(s)")
            args = ["close", str(output_close)] + close_files
            run_command(merge_script, args)
        else:
            print("‚ö†Ô∏è  Aucun fichier close trouv√©")
            with open(output_close, "w", encoding="utf-8") as f:
                f.write(
                    "name_from;name_to;distance;price1;price2;price3;price4;price5\n"
                )

        # ========================================
        # √âTAPE 5: Fusion finale - Open
        # ========================================
        print_banner("√âTAPE 5/6: Fusion finale des fichiers Open")

        open_files = find_csv_files(base_dir, "ASF_page*_data_price_open_2025.csv")
        output_open = base_dir / "ASF_data_price_open_2025.csv"

        if open_files:
            print(f"üìã {len(open_files)} fichier(s) trouv√©(s)")
            args = ["open", str(output_open)] + open_files
            run_command(merge_script, args)
        else:
            print("‚ö†Ô∏è  Aucun fichier open trouv√©")
            with open(output_open, "w", encoding="utf-8") as f:
                f.write("name;distance;price1;price2;price3;price4;price5\n")

        # ========================================
        # √âTAPE 6: Fusion finale - Toll Info + Validation finale
        # ========================================
        print_banner("√âTAPE 6/6: Fusion finale Toll Info & Validation")

        toll_info_files = find_csv_files(base_dir, "ASF_page*_toll_info.csv")
        output_toll_info = base_dir / "ASF_toll_info.csv"

        if toll_info_files:
            print(f"üìã {len(toll_info_files)} fichier(s) trouv√©(s)")
            args = ["toll_info", str(output_toll_info)] + toll_info_files
            run_command(merge_script, args)
        else:
            raise MetaScriptError(
                "‚ùå Aucun fichier toll_info trouv√©! Au moins un fichier toll_info est requis."
            )

        # Validation du triplet final
        print("\n  üîç Validation du triplet final...")
        args = [str(output_close), str(output_open), str(output_toll_info)]
        run_command(validate_script, args)

        # ========================================
        # R√âSUM√â FINAL
        # ========================================
        print_summary(output_close, output_open, output_toll_info)

        print("=" * 80)
        print("‚úÖ META-SCRIPT TERMIN√â AVEC SUCC√àS!")
        print("=" * 80)
        print("\nüéâ Tous les fichiers CSV consolid√©s ont √©t√© g√©n√©r√©s et valid√©s!")
        print(f"\nüìÇ Fichiers finaux dans: {base_dir}")
        print(f"üìÇ Fichiers par page dans: {base_dir}/page*/\n")

    except MetaScriptError as e:
        print(f"\n‚ùå ERREUR: {e}\n")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Ex√©cution interrompue par l'utilisateur\n")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå ERREUR INATTENDUE: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
