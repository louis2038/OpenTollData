# Meta-Script ASF - Documentation

## Vue d'ensemble

Ce dossier contient un syst√®me automatis√© pour traiter et consolider les donn√©es de tarifs autoroutiers ASF. Le syst√®me est compos√© de 4 scripts Python qui travaillent ensemble pour g√©n√©rer 3 fichiers CSV consolid√©s.

## Architecture

```
parse/ASF/
‚îú‚îÄ‚îÄ meta_asf.py                    # üéØ Script orchestrateur principal
‚îú‚îÄ‚îÄ run_all_page_scripts.py        # üîß Ex√©cuteur de tous les scripts de parsing
‚îú‚îÄ‚îÄ merge_csv_files.py             # üîó Fusion de fichiers CSV avec validation
‚îú‚îÄ‚îÄ validate_triplet.py            # ‚úÖ Validation de coh√©rence du triplet
‚îú‚îÄ‚îÄ page1/, page2/, ... pageN/     # Dossiers de donn√©es par page
‚îÇ   ‚îú‚îÄ‚îÄ raw_data/                  # Donn√©es brutes et scripts de parsing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parse_asf_*.py
‚îÇ   ‚îú‚îÄ‚îÄ ASF_pageN_data_price_close_2025.csv
‚îÇ   ‚îú‚îÄ‚îÄ ASF_pageN_data_price_open_2025.csv
‚îÇ   ‚îî‚îÄ‚îÄ ASF_pageN_toll_info.csv
‚îú‚îÄ‚îÄ ASF_data_price_close_2025.csv  # ‚ú® R√©sultat consolid√© (close)
‚îú‚îÄ‚îÄ ASF_data_price_open_2025.csv   # ‚ú® R√©sultat consolid√© (open)
‚îî‚îÄ‚îÄ ASF_toll_info.csv              # ‚ú® R√©sultat consolid√© (toll info)
```

## Fichiers de Sortie

### 1. `ASF_data_price_close_2025.csv`
Prix des syst√®mes de p√©age ferm√©s (entr√©e-sortie).
```
Format: name_from;name_to;distance;price1;price2;price3;price4;price5
```

### 2. `ASF_data_price_open_2025.csv`
Prix des syst√®mes de p√©age ouverts (tarif fixe).
```
Format: name;distance;price1;price2;price3;price4;price5
```

### 3. `ASF_toll_info.csv`
Informations sur les p√©ages avec m√©tadonn√©es OSM.
```
Format: name;osm_name;operator_ref;lat;lon;nbs_booth;booth_node_id;booth_way_id;type;operator_osm
```

**Note**: Les champs `distance`, `operator_ref`, et `operator_osm` sont optionnels.

## Utilisation

### Workflow Complet (Recommand√©)

Pour ex√©cuter l'ensemble du workflow (parsing + fusion + validation) :

```bash
cd parse/ASF
python3 meta_asf.py
```

**Ce script va :**
1. ‚úÖ Ex√©cuter tous les scripts de parsing dans `page*/raw_data/`
2. ‚úÖ Fusionner tous les fichiers close
3. ‚úÖ Fusionner tous les fichiers open
4. ‚úÖ Fusionner tous les fichiers toll_info avec validation OSM
5. ‚úÖ Valider la coh√©rence du triplet final

### Scripts Individuels

#### 1. Ex√©cuter uniquement les scripts de parsing

```bash
python3 run_all_page_scripts.py
```

#### 2. Fusionner des fichiers CSV manuellement

```bash
# Fusion de fichiers close
python3 merge_csv_files.py close output.csv input1.csv input2.csv ...

# Fusion de fichiers open
python3 merge_csv_files.py open output.csv input1.csv input2.csv ...

# Fusion de fichiers toll_info (avec validation OSM)
python3 merge_csv_files.py toll_info output.csv input1.csv input2.csv ...
```

#### 3. Valider la coh√©rence d'un triplet

```bash
python3 validate_triplet.py close.csv open.csv toll_info.csv
```

## Fonctionnalit√©s Cl√©s

### üîç D√©tection Automatique du D√©limiteur
Les scripts d√©tectent automatiquement si les CSV d'entr√©e utilisent `;` ou `,` comme d√©limiteur.

### üõ°Ô∏è Validation Stricte
- **Toll Info**: V√©rifie que le m√™me `name` (cl√© primaire) a toujours les m√™mes IDs OSM (`booth_node_id`, `booth_way_id`)
- **Triplet**: V√©rifie que tous les noms dans les prix existent dans toll_info et vice-versa

### ‚ö†Ô∏è Gestion des Erreurs
Le meta-script s'arr√™te imm√©diatement en cas d'erreur et affiche un message d√©taill√©.

### üßπ D√©doublonnage Automatique
Les lignes dupliqu√©es sont automatiquement supprim√©es lors de la fusion.

### üìä Rapports D√©taill√©s
Chaque √©tape affiche des statistiques claires sur le traitement.

## Format des Fichiers

### Encodage
Tous les fichiers de sortie sont encod√©s en **UTF-8**.

### D√©limiteur
Tous les fichiers de sortie utilisent le d√©limiteur **`;`** (point-virgule).

### Normalisation des Noms
Les noms de stations doivent √™tre normalis√©s avec la fonction suivante :

```python
import re
import unicodedata

def normalize_name(s: str) -> str:
    if not s:
        return ""
    s = unicodedata.normalize("NFKC", s)
    s = "".join(
        c for c in unicodedata.normalize("NFD", s)
        if unicodedata.category(c) != "Mn"
    )
    s = re.sub(r"[^A-Za-z0-9]", " ", s)
    s = re.sub(r"\s+", " ", s)
    s = s.strip()
    return s.upper()
```

**Le champ `name` est la cl√© primaire du syst√®me et doit √™tre unique et coh√©rent.**

## Validation des Donn√©es

### Validation des IDs OSM (toll_info)

Le script `merge_csv_files.py` v√©rifie que pour un m√™me `name`, les IDs OSM sont identiques :
- `booth_node_id` doit √™tre identique
- `booth_way_id` doit √™tre identique

**Exemple d'erreur :**
```
‚ùå ERREUR: La station 'PEAGE DE VIENNE' a des IDs OSM diff√©rents:
  - Ligne 5: booth_node_id='[123, 456]', booth_way_id='[]'
  - Ligne 12: booth_node_id='[123]', booth_way_id='[789]'
```

### Validation du Triplet

Le script `validate_triplet.py` v√©rifie :
1. Tous les noms dans `close` et `open` existent dans `toll_info`
2. Tous les noms dans `toll_info` sont utilis√©s dans au moins un fichier de prix

**Exemple d'erreur :**
```
‚ùå 5 station(s) pr√©sente(s) dans les fichiers de prix mais ABSENTE(S) de toll_info:
  - STATION_A [close]
  - STATION_B [open]
  ...
```

## D√©pannage

### Probl√®me : D√©limiteurs mixtes dans un fichier

**Sympt√¥me** : Le fichier a des `;` dans l'en-t√™te mais des `,` dans les donn√©es.

**Solution** : Corriger le script de parsing qui g√©n√®re ce fichier pour utiliser un d√©limiteur coh√©rent.

### Probl√®me : Station dans les prix mais pas dans toll_info

**Sympt√¥me** : La validation √©choue avec des noms manquants.

**Solutions possibles** :
1. V√©rifier que le nom est normalis√© de la m√™me fa√ßon
2. Ajouter la station manquante dans le fichier toll_info appropri√©
3. V√©rifier s'il y a une erreur de typo dans le nom

### Probl√®me : Station dans toll_info mais pas dans les prix

**Sympt√¥me** : La validation √©choue avec des stations non utilis√©es.

**Solutions possibles** :
1. C'est normal si certaines pages n'ont pas encore de script de parsing
2. V√©rifier si la station devrait avoir des prix associ√©s
3. Supprimer la station de toll_info si elle n'est plus utilis√©e

## Scripts de Parsing Individuels

Les scripts de parsing par page se trouvent dans `page*/raw_data/parse_asf_*.py`.

**R√®gles importantes :**
- Utiliser la fonction `normalize_name()` pour tous les noms de stations
- G√©n√©rer les 3 fichiers CSV (ou au minimum toll_info)
- Utiliser le d√©limiteur `;` pour tous les fichiers de sortie
- Encoder en UTF-8

## Exemple de Workflow Complet

```bash
# 1. Cr√©er ou modifier un script de parsing
vim page_nouvelle/raw_data/parse_asf_page_nouvelle.py

# 2. Tester le script individuellement
cd page_nouvelle/raw_data
python3 parse_asf_page_nouvelle.py

# 3. V√©rifier les fichiers g√©n√©r√©s
ls -l ../ASF_page_nouvelle_*.csv

# 4. Ex√©cuter le meta-script pour tout consolider
cd ../..
python3 meta_asf.py

# 5. V√©rifier les r√©sultats
head ASF_data_price_close_2025.csv
head ASF_data_price_open_2025.csv
head ASF_toll_info.csv
```

## Auteur

Cr√©√© par OpenCode - Janvier 2026

## Licence

Fait partie du projet TollData - Donn√©es ouvertes sur les p√©ages autoroutiers fran√ßais.
